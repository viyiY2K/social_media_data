#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
çŸ¥ä¹ç²‰ä¸æ•°è·å–å·¥å…· - ä¼˜åŒ–ç‰ˆ
åŸºäºMediaCrawlerçš„å®ç°æ€è·¯
"""

import asyncio
import csv
import re
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

try:
    from playwright.async_api import async_playwright, BrowserContext, Page
except ImportError:
    print("è¯·å…ˆå®‰è£…playwright: pip install playwright")
    print("ç„¶åå®‰è£…æµè§ˆå™¨: playwright install")
    sys.exit(1)

class ZhihuOptimizedCrawler:
    def __init__(self):
        self.browser_context: Optional[BrowserContext] = None
        self.context_page: Optional[Page] = None
        self.user_data_dir = Path.cwd() / "browser_data" / "zhihu"
        
    async def init_browser(self, headless: bool = False):
        """åˆå§‹åŒ–æµè§ˆå™¨"""
        playwright = await async_playwright().start()
        
        # ç¡®ä¿ç”¨æˆ·æ•°æ®ç›®å½•å­˜åœ¨
        self.user_data_dir.mkdir(parents=True, exist_ok=True)
        
        # æµè§ˆå™¨å¯åŠ¨å‚æ•°
        browser_args = [
            "--no-sandbox",
            "--disable-setuid-sandbox",
            "--disable-dev-shm-usage",
            "--disable-blink-features=AutomationControlled",
            "--disable-web-security",
            "--allow-running-insecure-content",
            "--no-first-run",
            "--disable-features=VizDisplayCompositor"
        ]
        
        # å¯åŠ¨æŒä¹…åŒ–æµè§ˆå™¨ä¸Šä¸‹æ–‡
        self.browser_context = await playwright.chromium.launch_persistent_context(
            user_data_dir=str(self.user_data_dir),
            headless=headless,
            args=browser_args,
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            locale="zh-CN",
            timezone_id="Asia/Shanghai"
        )
        
        # è·å–é¡µé¢
        if self.browser_context.pages:
            self.context_page = self.browser_context.pages[0]
        else:
            self.context_page = await self.browser_context.new_page()
            
        # æ³¨å…¥åæ£€æµ‹è„šæœ¬
        await self.context_page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
            window.chrome = { runtime: {} };
        """)
        
        print("âœ… æµè§ˆå™¨åˆå§‹åŒ–å®Œæˆ")
        
    async def login(self) -> bool:
        """ç™»å½•çŸ¥ä¹"""
        try:
            await self.context_page.goto("https://www.zhihu.com")
            await asyncio.sleep(3)
            
            # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•
            if await self._is_logged_in():
                print("âœ… å·²ç™»å½•")
                return True
                
            print("ğŸ” éœ€è¦ç™»å½•ï¼Œè¯·åœ¨æµè§ˆå™¨ä¸­å®Œæˆç™»å½•...")
            print("æ¨èä½¿ç”¨æ‰‹æœºå·+çŸ­ä¿¡éªŒè¯ç ç™»å½•")
            
            # ç­‰å¾…ç”¨æˆ·ç™»å½•
            while True:
                await asyncio.sleep(5)
                if await self._is_logged_in():
                    print("âœ… ç™»å½•æˆåŠŸï¼")
                    return True
                    
        except Exception as e:
            print(f"âŒ ç™»å½•å¤±è´¥: {e}")
            return False
            
    async def _is_logged_in(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦å·²ç™»å½•"""
        try:
            selectors = [
                ".AppHeader-userInfo",
                ".Avatar",
                "[data-za-detail-view-id='2267']"
            ]
            
            for selector in selectors:
                element = await self.context_page.query_selector(selector)
                if element:
                    return True
                    
            return False
        except:
            return False
            
    async def get_user_followers(self, user_slug: str) -> Dict:
        """è·å–ç”¨æˆ·ç²‰ä¸æ•° - ä¼˜åŒ–ç‰ˆ"""
        try:
            url = f"https://www.zhihu.com/people/{user_slug}"
            print(f"ğŸ“ è®¿é—®: {url}")
            
            await self.context_page.goto(url, wait_until="networkidle")
            await asyncio.sleep(3)  # ç­‰å¾…æ•°æ®åŠ è½½
            
            # è·å–ç”¨æˆ·å
            username = await self._get_username()
            
            # è·å–ç²‰ä¸æ•° - ä½¿ç”¨ä¼˜åŒ–çš„NumberBoardæ–¹æ³•
            followers = await self._get_followers_count_optimized()
            
            return {
                "username": username,
                "followers": followers,
                "platform": "çŸ¥ä¹",
                "date": datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            }
            
        except Exception as e:
            print(f"âŒ è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}")
            return {}
            
    async def _get_followers_count_optimized(self) -> int:
        """è·å–ç²‰ä¸æ•° - ä¼˜åŒ–ç‰ˆï¼ˆä¸“æ³¨NumberBoardæ–¹æ³•ï¼‰"""
        try:
            # ç­‰å¾…NumberBoardå…ƒç´ åŠ è½½
            await self.context_page.wait_for_selector(".NumberBoard-item", timeout=10000)
            
            # è·å–æ‰€æœ‰NumberBoardå…ƒç´ 
            elements = await self.context_page.query_selector_all(".NumberBoard-item")
            
            for element in elements:
                text = await element.inner_text()
                # æŸ¥æ‰¾åŒ…å«"å…³æ³¨è€…"çš„å…ƒç´ 
                if "å…³æ³¨è€…" in text:
                    followers_count = self._parse_followers_text(text)
                    if followers_count > 0:
                        return followers_count
                        
            # å¦‚æœNumberBoardæ–¹æ³•å¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            print("âš ï¸ NumberBoardæ–¹æ³•æœªæ‰¾åˆ°å…³æ³¨è€…ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
            return await self._get_followers_fallback()
            
        except Exception as e:
            print(f"âš ï¸ NumberBoardæ–¹æ³•å‡ºé”™: {e}ï¼Œå°è¯•å¤‡ç”¨æ–¹æ³•...")
            return await self._get_followers_fallback()
            
    async def _get_followers_fallback(self) -> int:
        """å¤‡ç”¨æ–¹æ³•ï¼šJavaScriptæœç´¢"""
        try:
            js_result = await self.context_page.evaluate("""
                () => {
                    const elements = document.querySelectorAll('*');
                    for (let element of elements) {
                        const text = element.textContent || '';
                        if (text.includes('å…³æ³¨è€…') && text.length < 50) {
                            return text.trim();
                        }
                    }
                    return null;
                }
            """)
            
            if js_result:
                return self._parse_followers_text(js_result)
            return 0
        except:
            return 0
            
    def _parse_followers_text(self, text: str) -> int:
        """è§£æç²‰ä¸æ•°æ–‡æœ¬ï¼Œæ”¯æŒä¸‡ã€åƒç­‰å•ä½"""
        try:
            # æ¸…ç†æ–‡æœ¬
            text = text.strip().replace(',', '').replace('ï¼Œ', '').replace('\n', ' ')
            
            # åŒ¹é…æ•°å­—+å•ä½çš„æ ¼å¼
            patterns = [
                r'([\d.]+)\s*ä¸‡',  # X.Xä¸‡
                r'([\d.]+)\s*åƒ',  # X.Xåƒ
                r'(\d+)',         # çº¯æ•°å­—
            ]
            
            for pattern in patterns:
                match = re.search(pattern, text)
                if match:
                    number_str = match.group(1)
                    number = float(number_str)
                    
                    if 'ä¸‡' in text:
                        return int(number * 10000)
                    elif 'åƒ' in text:
                        return int(number * 1000)
                    else:
                        return int(number)
                        
            return 0
        except:
            return 0
            
    async def _get_username(self) -> str:
        """è·å–ç”¨æˆ·å"""
        try:
            # ä»æ ‡é¢˜è·å–
            title = await self.context_page.title()
            if " - çŸ¥ä¹" in title:
                username = title.replace(" - çŸ¥ä¹", "").strip()
                # æ¸…ç†æ‹¬å·å†…çš„æ¶ˆæ¯æç¤º
                username = self._clean_username(username)
                return username
                
            # ä»å…ƒç´ è·å–
            selectors = [".ProfileHeader-name", ".UserLink-link"]
            for selector in selectors:
                element = await self.context_page.query_selector(selector)
                if element:
                    text = await element.inner_text()
                    if text.strip():
                        return self._clean_username(text.strip())
                        
            return "æœªçŸ¥ç”¨æˆ·"
        except:
            return "æœªçŸ¥ç”¨æˆ·"
            
    def _clean_username(self, username: str) -> str:
        """æ¸…ç†ç”¨æˆ·åä¸­çš„æ¶ˆæ¯æç¤ºç­‰æ— å…³å†…å®¹"""
        try:
            import re
            # ç§»é™¤æ‹¬å·å†…çš„æ¶ˆæ¯æç¤ºï¼Œå¦‚ "(2 å°ç§ä¿¡ / 4 æ¡æ¶ˆæ¯) æå› " -> "æå› "
            cleaned = re.sub(r'\([^)]*å°ç§ä¿¡[^)]*\)\s*', '', username)
            # ç§»é™¤å…¶ä»–å¯èƒ½çš„æ‹¬å·å†…å®¹
            cleaned = re.sub(r'\([^)]*æ¡æ¶ˆæ¯[^)]*\)\s*', '', cleaned)
            # ç§»é™¤å¤šä½™çš„ç©ºæ ¼
            cleaned = cleaned.strip()
            return cleaned if cleaned else username
        except:
            return username
            
    def append_to_csv(self, data: Dict, filename: str = "followers.csv"):
        """è¿½åŠ æ•°æ®åˆ°CSVæ–‡ä»¶"""
        try:
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            file_exists = Path(filename).exists()
            
            with open(filename, "a", newline="", encoding="utf-8") as f:
                fieldnames = ["æ—¥æœŸ", "è´¦å·å", "å¹³å°", "ç²‰ä¸æ•°"]
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                
                # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå†™å…¥è¡¨å¤´
                if not file_exists:
                    writer.writeheader()
                
                # å†™å…¥æ•°æ®
                writer.writerow({
                    "æ—¥æœŸ": data["date"],
                    "è´¦å·å": data["username"],
                    "å¹³å°": data["platform"],
                    "ç²‰ä¸æ•°": data["followers"]
                })
                
            print(f"âœ… æ•°æ®å·²è¿½åŠ åˆ° {filename}")
            
        except Exception as e:
            print(f"âŒ å†™å…¥CSVå¤±è´¥: {e}")
            
    async def close(self):
        """å…³é—­æµè§ˆå™¨"""
        if self.browser_context:
            await self.browser_context.close()
            print("âœ… æµè§ˆå™¨å·²å…³é—­")

# åœ¨æ–‡ä»¶æœ«å°¾çš„ main() å‡½æ•°ä¹‹å‰æ·»åŠ è¿™ä¸ªå¯¼å‡ºå‡½æ•°

# å¯¼å‡ºå‡½æ•°ï¼šè·å–çŸ¥ä¹æ•°æ®
async def get_zhihu_data(user_slugs):
    """
    è·å–çŸ¥ä¹ç”¨æˆ·æ•°æ®
    :param user_slugs: ç”¨æˆ·slugåˆ—è¡¨
    :return: (æˆåŠŸæ•°æ®åˆ—è¡¨, å¤±è´¥è´¦å·åˆ—è¡¨)
    """
    print("ğŸ” å¼€å§‹è·å–çŸ¥ä¹æ•°æ®...")
    
    crawler = ZhihuOptimizedCrawler()
    data_list = []
    failed_accounts = []
    
    try:
        # åˆå§‹åŒ–æµè§ˆå™¨
        await crawler.init_browser(headless=False)
        
        # ç™»å½•
        if not await crawler.login():
            print("âŒ çŸ¥ä¹ç™»å½•å¤±è´¥")
            return [], user_slugs
            
        # è·å–ç”¨æˆ·æ•°æ®
        for user_slug in user_slugs:
            print(f"ğŸ¯ å¤„ç†çŸ¥ä¹ç”¨æˆ·: {user_slug}")
            user_data = await crawler.get_user_followers(user_slug)
            
            if user_data and user_data.get("followers", 0) > 0:
                data_list.append({
                    'æ—¥æœŸ': user_data["date"],
                    'è´¦å·å': user_data["username"],
                    'å¹³å°': user_data["platform"],
                    'ç²‰ä¸æ•°': user_data["followers"]
                })
                print(f"âœ… {user_data['username']}: {user_data['followers']:,} ç²‰ä¸")
            else:
                print(f"âŒ è·å–å¤±è´¥: {user_slug}")
                failed_accounts.append(user_slug)
                
            await asyncio.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
            
    except Exception as e:
        print(f"âŒ çŸ¥ä¹æ•°æ®è·å–å‡ºé”™: {e}")
        failed_accounts.extend(user_slugs)
    finally:
        await crawler.close()
        
    return data_list, failed_accounts

async def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®
    USER_SLUGS = ["zhi-yin-233"]  # è¦è·å–çš„ç”¨æˆ·åˆ—è¡¨
    HEADLESS = False  # æ˜¯å¦æ— å¤´æ¨¡å¼
    CSV_FILENAME = "followers.csv"  # CSVæ–‡ä»¶å
    
    print("=== çŸ¥ä¹ç²‰ä¸æ•°è·å–å·¥å…·ï¼ˆä¼˜åŒ–ç‰ˆï¼‰===")
    print(f"ç›®æ ‡ç”¨æˆ·: {USER_SLUGS}")
    print(f"è¾“å‡ºæ–‡ä»¶: {CSV_FILENAME}")
    print()
    
    crawler = ZhihuOptimizedCrawler()
    
    try:
        # åˆå§‹åŒ–æµè§ˆå™¨
        await crawler.init_browser(headless=HEADLESS)
        
        # ç™»å½•
        if not await crawler.login():
            print("âŒ ç™»å½•å¤±è´¥ï¼Œé€€å‡ºç¨‹åº")
            return
            
        # è·å–ç”¨æˆ·æ•°æ®
        success_count = 0
        for user_slug in USER_SLUGS:
            print(f"\nğŸ¯ å¤„ç†ç”¨æˆ·: {user_slug}")
            user_data = await crawler.get_user_followers(user_slug)
            
            if user_data and user_data.get("followers", 0) > 0:
                # è¿½åŠ åˆ°CSVæ–‡ä»¶
                crawler.append_to_csv(user_data, CSV_FILENAME)
                print(f"âœ… {user_data['username']}: {user_data['followers']:,} ç²‰ä¸")
                success_count += 1
            else:
                print(f"âŒ è·å–å¤±è´¥: {user_slug}")
                
            await asyncio.sleep(2)  # é¿å…è¯·æ±‚è¿‡å¿«
            
        print(f"\nğŸ‰ å®Œæˆï¼æˆåŠŸè·å– {success_count}/{len(USER_SLUGS)} ä¸ªç”¨æˆ·çš„æ•°æ®")
        print(f"ğŸ“„ æ•°æ®å·²ä¿å­˜åˆ°: {CSV_FILENAME}")
            
    except Exception as e:
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
    finally:
        await crawler.close()

if __name__ == "__main__":
    asyncio.run(main())